{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b45c80bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install snscrape\n",
    "# !pip install git+https://github.com/JustAnotherArchivist/snscrape.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bd9241",
   "metadata": {},
   "source": [
    "## Install necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66c0b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "# nlp\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "# text representation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "#models\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "# metrics\n",
    "from sklearn.metrics import silhouette_score\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "788796cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas\n",
    "channel = 'CNN'\n",
    "start_date='2021-12-13'\n",
    "end_date='2021-12-14'\n",
    "# Creating list to append tweet data to\n",
    "tweets_list2 = []\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'from:{channel} since:{start_date} until:{end_date}').get_items()):\n",
    "    if i>50:\n",
    "        break\n",
    "    tweets_list2.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "    \n",
    "# Creating a dataframe from the tweets list above\n",
    "tweets_df2 = pd.DataFrame(tweets_list2, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec8a31d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-13 23:55:10+00:00</td>\n",
       "      <td>1470542846109392898</td>\n",
       "      <td>Former Brooklyn Center, Minnesota, police offi...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-13 23:44:12+00:00</td>\n",
       "      <td>1470540084873244672</td>\n",
       "      <td>The Omicron variant of coronavirus is spreadin...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-13 23:33:05+00:00</td>\n",
       "      <td>1470537290283982857</td>\n",
       "      <td>Hundreds of millions of devices around the wor...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-13 23:22:50+00:00</td>\n",
       "      <td>1470534710669590529</td>\n",
       "      <td>Defense Secretary Lloyd Austin has decided tha...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-13 23:12:11+00:00</td>\n",
       "      <td>1470532029209104386</td>\n",
       "      <td>After all these years, Bing Crosby still spurs...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-12-13 22:55:44+00:00</td>\n",
       "      <td>1470527887971336199</td>\n",
       "      <td>The CDC has added three nations to its highest...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-12-13 22:35:34+00:00</td>\n",
       "      <td>1470522815514386433</td>\n",
       "      <td>\"That little $3 whistle is what saved us from ...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-12-13 22:16:04+00:00</td>\n",
       "      <td>1470517906287042562</td>\n",
       "      <td>Former Minneapolis police officer Derek Chauvi...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-12-13 22:01:04+00:00</td>\n",
       "      <td>1470514133099556864</td>\n",
       "      <td>Victims of Larry Nassar, the former Olympic do...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-12-13 21:45:08+00:00</td>\n",
       "      <td>1470510122145300480</td>\n",
       "      <td>Individual users, not tech platforms, shoulder...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-12-13 21:33:28+00:00</td>\n",
       "      <td>1470507184933031950</td>\n",
       "      <td>Astronomers have found evidence of an ancient ...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-12-13 21:16:07+00:00</td>\n",
       "      <td>1470502819522301964</td>\n",
       "      <td>The FBI is offering a reward for information r...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-12-13 21:01:06+00:00</td>\n",
       "      <td>1470499040072712194</td>\n",
       "      <td>The Occupational Safety and Health Administrat...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-12-13 20:46:03+00:00</td>\n",
       "      <td>1470495252284911639</td>\n",
       "      <td>\"The Dr. Oz Show\" will end in its thirteenth s...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-12-13 20:30:01+00:00</td>\n",
       "      <td>1470491219998429184</td>\n",
       "      <td>JUST IN: The Supreme Court has turned away two...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-12-13 20:15:06+00:00</td>\n",
       "      <td>1470487464921939969</td>\n",
       "      <td>Sen. Joe Manchin indicated that a significant ...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-12-13 20:00:28+00:00</td>\n",
       "      <td>1470483783350685699</td>\n",
       "      <td>Biden's big infrastructure plan, which was pas...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-12-13 19:35:18+00:00</td>\n",
       "      <td>1470477448550748169</td>\n",
       "      <td>An atmospheric river â€” a plume of moisture, si...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-12-13 19:16:02+00:00</td>\n",
       "      <td>1470472599440396298</td>\n",
       "      <td>President Biden will travel to Kentucky later ...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-12-13 19:00:03+00:00</td>\n",
       "      <td>1470468575853002755</td>\n",
       "      <td>Parents are set to get their last monthly infu...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021-12-13 18:45:10+00:00</td>\n",
       "      <td>1470464829819432961</td>\n",
       "      <td>Bond was set at $7 million for Alex Murdaugh, ...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021-12-13 18:00:10+00:00</td>\n",
       "      <td>1470453505815105542</td>\n",
       "      <td>Two officers were caught in a deadly tornado t...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2021-12-13 17:49:08+00:00</td>\n",
       "      <td>1470450732289736706</td>\n",
       "      <td>CNN Heroes 2021: Be inspired by everyday peopl...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-12-13 17:45:08+00:00</td>\n",
       "      <td>1470449725233061890</td>\n",
       "      <td>In 2013, Anthony Bourdain traveled to Jerusale...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021-12-13 17:32:04+00:00</td>\n",
       "      <td>1470446434579369992</td>\n",
       "      <td>Some of the world's richest men are squaring o...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021-12-13 17:30:04+00:00</td>\n",
       "      <td>1470445933339029507</td>\n",
       "      <td>It may seem silly to talk about Princess Diana...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2021-12-13 17:15:11+00:00</td>\n",
       "      <td>1470442187271847936</td>\n",
       "      <td>Kim Kardashian has passed a law exam and moved...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2021-12-13 17:00:18+00:00</td>\n",
       "      <td>1470438439887773702</td>\n",
       "      <td>Every day, thousands of fishing boats around t...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2021-12-13 16:45:05+00:00</td>\n",
       "      <td>1470434613415882762</td>\n",
       "      <td>Bear cub vs inflatable reindeer: Watch as bear...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021-12-13 16:30:11+00:00</td>\n",
       "      <td>1470430861023666181</td>\n",
       "      <td>The Geminid meteor shower, which NASA calls \"o...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021-12-13 16:15:03+00:00</td>\n",
       "      <td>1470427054239801356</td>\n",
       "      <td>He killed some of Coke's most beloved brands l...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2021-12-13 16:00:14+00:00</td>\n",
       "      <td>1470423325872644100</td>\n",
       "      <td>Some of us are now secretly (or not-so-secretl...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2021-12-13 15:45:04+00:00</td>\n",
       "      <td>1470419506975682562</td>\n",
       "      <td>Kevin Durant scored an NBA season high 51 poin...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2021-12-13 15:30:13+00:00</td>\n",
       "      <td>1470415770027008011</td>\n",
       "      <td>Doja Cat has announced she's dropped out of th...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2021-12-13 15:15:06+00:00</td>\n",
       "      <td>1470411968704131073</td>\n",
       "      <td>Biden's big infrastructure plan, which was pas...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2021-12-13 15:08:13+00:00</td>\n",
       "      <td>1470410232690003971</td>\n",
       "      <td>See the full list of nominees for the 79th Ann...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2021-12-13 15:00:11+00:00</td>\n",
       "      <td>1470408214965542919</td>\n",
       "      <td>Apple is on the verge of yet another major mil...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2021-12-13 14:45:06+00:00</td>\n",
       "      <td>1470404417170116610</td>\n",
       "      <td>A factory worker trapped under 5 feet of debri...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2021-12-13 14:30:08+00:00</td>\n",
       "      <td>1470400652534853638</td>\n",
       "      <td>There are many tips for beating the afternoon ...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2021-12-13 14:15:07+00:00</td>\n",
       "      <td>1470396869922766851</td>\n",
       "      <td>US businesses to lose a collective 3.1 million...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2021-12-13 14:01:02+00:00</td>\n",
       "      <td>1470393327992324105</td>\n",
       "      <td>Time magazine has named Elon Musk -- CEO of Te...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2021-12-13 13:45:05+00:00</td>\n",
       "      <td>1470389315326943233</td>\n",
       "      <td>Meadows said National Guard would be ready to ...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2021-12-13 13:38:02+00:00</td>\n",
       "      <td>1470387538200346624</td>\n",
       "      <td>Since the 19th century, native oyster populati...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2021-12-13 13:30:11+00:00</td>\n",
       "      <td>1470385563207454722</td>\n",
       "      <td>Vice President Kamala Harris will announce a n...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2021-12-13 13:15:07+00:00</td>\n",
       "      <td>1470381771057418251</td>\n",
       "      <td>Before Sunday, Tom Brady had almost every all-...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2021-12-13 13:01:02+00:00</td>\n",
       "      <td>1470378226035867655</td>\n",
       "      <td>Each week, Shirley Raines and her team of volu...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2021-12-13 12:45:04+00:00</td>\n",
       "      <td>1470374208127516673</td>\n",
       "      <td>Peloton has released a new ad in response to t...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2021-12-13 12:31:03+00:00</td>\n",
       "      <td>1470370681602859017</td>\n",
       "      <td>One of the Louisville detectives who fatally s...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2021-12-13 12:15:03+00:00</td>\n",
       "      <td>1470366654668365824</td>\n",
       "      <td>Gigantic superyachts have long been nicknamed ...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2021-12-13 12:00:10+00:00</td>\n",
       "      <td>1470362912028078086</td>\n",
       "      <td>From Lisa Ling to the West Wing, A.C. to D.C.,...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2021-12-13 11:45:06+00:00</td>\n",
       "      <td>1470359119274160131</td>\n",
       "      <td>Michigan high school shooting suspect Ethan Cr...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Datetime             Tweet Id  \\\n",
       "0  2021-12-13 23:55:10+00:00  1470542846109392898   \n",
       "1  2021-12-13 23:44:12+00:00  1470540084873244672   \n",
       "2  2021-12-13 23:33:05+00:00  1470537290283982857   \n",
       "3  2021-12-13 23:22:50+00:00  1470534710669590529   \n",
       "4  2021-12-13 23:12:11+00:00  1470532029209104386   \n",
       "5  2021-12-13 22:55:44+00:00  1470527887971336199   \n",
       "6  2021-12-13 22:35:34+00:00  1470522815514386433   \n",
       "7  2021-12-13 22:16:04+00:00  1470517906287042562   \n",
       "8  2021-12-13 22:01:04+00:00  1470514133099556864   \n",
       "9  2021-12-13 21:45:08+00:00  1470510122145300480   \n",
       "10 2021-12-13 21:33:28+00:00  1470507184933031950   \n",
       "11 2021-12-13 21:16:07+00:00  1470502819522301964   \n",
       "12 2021-12-13 21:01:06+00:00  1470499040072712194   \n",
       "13 2021-12-13 20:46:03+00:00  1470495252284911639   \n",
       "14 2021-12-13 20:30:01+00:00  1470491219998429184   \n",
       "15 2021-12-13 20:15:06+00:00  1470487464921939969   \n",
       "16 2021-12-13 20:00:28+00:00  1470483783350685699   \n",
       "17 2021-12-13 19:35:18+00:00  1470477448550748169   \n",
       "18 2021-12-13 19:16:02+00:00  1470472599440396298   \n",
       "19 2021-12-13 19:00:03+00:00  1470468575853002755   \n",
       "20 2021-12-13 18:45:10+00:00  1470464829819432961   \n",
       "21 2021-12-13 18:00:10+00:00  1470453505815105542   \n",
       "22 2021-12-13 17:49:08+00:00  1470450732289736706   \n",
       "23 2021-12-13 17:45:08+00:00  1470449725233061890   \n",
       "24 2021-12-13 17:32:04+00:00  1470446434579369992   \n",
       "25 2021-12-13 17:30:04+00:00  1470445933339029507   \n",
       "26 2021-12-13 17:15:11+00:00  1470442187271847936   \n",
       "27 2021-12-13 17:00:18+00:00  1470438439887773702   \n",
       "28 2021-12-13 16:45:05+00:00  1470434613415882762   \n",
       "29 2021-12-13 16:30:11+00:00  1470430861023666181   \n",
       "30 2021-12-13 16:15:03+00:00  1470427054239801356   \n",
       "31 2021-12-13 16:00:14+00:00  1470423325872644100   \n",
       "32 2021-12-13 15:45:04+00:00  1470419506975682562   \n",
       "33 2021-12-13 15:30:13+00:00  1470415770027008011   \n",
       "34 2021-12-13 15:15:06+00:00  1470411968704131073   \n",
       "35 2021-12-13 15:08:13+00:00  1470410232690003971   \n",
       "36 2021-12-13 15:00:11+00:00  1470408214965542919   \n",
       "37 2021-12-13 14:45:06+00:00  1470404417170116610   \n",
       "38 2021-12-13 14:30:08+00:00  1470400652534853638   \n",
       "39 2021-12-13 14:15:07+00:00  1470396869922766851   \n",
       "40 2021-12-13 14:01:02+00:00  1470393327992324105   \n",
       "41 2021-12-13 13:45:05+00:00  1470389315326943233   \n",
       "42 2021-12-13 13:38:02+00:00  1470387538200346624   \n",
       "43 2021-12-13 13:30:11+00:00  1470385563207454722   \n",
       "44 2021-12-13 13:15:07+00:00  1470381771057418251   \n",
       "45 2021-12-13 13:01:02+00:00  1470378226035867655   \n",
       "46 2021-12-13 12:45:04+00:00  1470374208127516673   \n",
       "47 2021-12-13 12:31:03+00:00  1470370681602859017   \n",
       "48 2021-12-13 12:15:03+00:00  1470366654668365824   \n",
       "49 2021-12-13 12:00:10+00:00  1470362912028078086   \n",
       "50 2021-12-13 11:45:06+00:00  1470359119274160131   \n",
       "\n",
       "                                                 Text Username  \n",
       "0   Former Brooklyn Center, Minnesota, police offi...      CNN  \n",
       "1   The Omicron variant of coronavirus is spreadin...      CNN  \n",
       "2   Hundreds of millions of devices around the wor...      CNN  \n",
       "3   Defense Secretary Lloyd Austin has decided tha...      CNN  \n",
       "4   After all these years, Bing Crosby still spurs...      CNN  \n",
       "5   The CDC has added three nations to its highest...      CNN  \n",
       "6   \"That little $3 whistle is what saved us from ...      CNN  \n",
       "7   Former Minneapolis police officer Derek Chauvi...      CNN  \n",
       "8   Victims of Larry Nassar, the former Olympic do...      CNN  \n",
       "9   Individual users, not tech platforms, shoulder...      CNN  \n",
       "10  Astronomers have found evidence of an ancient ...      CNN  \n",
       "11  The FBI is offering a reward for information r...      CNN  \n",
       "12  The Occupational Safety and Health Administrat...      CNN  \n",
       "13  \"The Dr. Oz Show\" will end in its thirteenth s...      CNN  \n",
       "14  JUST IN: The Supreme Court has turned away two...      CNN  \n",
       "15  Sen. Joe Manchin indicated that a significant ...      CNN  \n",
       "16  Biden's big infrastructure plan, which was pas...      CNN  \n",
       "17  An atmospheric river â€” a plume of moisture, si...      CNN  \n",
       "18  President Biden will travel to Kentucky later ...      CNN  \n",
       "19  Parents are set to get their last monthly infu...      CNN  \n",
       "20  Bond was set at $7 million for Alex Murdaugh, ...      CNN  \n",
       "21  Two officers were caught in a deadly tornado t...      CNN  \n",
       "22  CNN Heroes 2021: Be inspired by everyday peopl...      CNN  \n",
       "23  In 2013, Anthony Bourdain traveled to Jerusale...      CNN  \n",
       "24  Some of the world's richest men are squaring o...      CNN  \n",
       "25  It may seem silly to talk about Princess Diana...      CNN  \n",
       "26  Kim Kardashian has passed a law exam and moved...      CNN  \n",
       "27  Every day, thousands of fishing boats around t...      CNN  \n",
       "28  Bear cub vs inflatable reindeer: Watch as bear...      CNN  \n",
       "29  The Geminid meteor shower, which NASA calls \"o...      CNN  \n",
       "30  He killed some of Coke's most beloved brands l...      CNN  \n",
       "31  Some of us are now secretly (or not-so-secretl...      CNN  \n",
       "32  Kevin Durant scored an NBA season high 51 poin...      CNN  \n",
       "33  Doja Cat has announced she's dropped out of th...      CNN  \n",
       "34  Biden's big infrastructure plan, which was pas...      CNN  \n",
       "35  See the full list of nominees for the 79th Ann...      CNN  \n",
       "36  Apple is on the verge of yet another major mil...      CNN  \n",
       "37  A factory worker trapped under 5 feet of debri...      CNN  \n",
       "38  There are many tips for beating the afternoon ...      CNN  \n",
       "39  US businesses to lose a collective 3.1 million...      CNN  \n",
       "40  Time magazine has named Elon Musk -- CEO of Te...      CNN  \n",
       "41  Meadows said National Guard would be ready to ...      CNN  \n",
       "42  Since the 19th century, native oyster populati...      CNN  \n",
       "43  Vice President Kamala Harris will announce a n...      CNN  \n",
       "44  Before Sunday, Tom Brady had almost every all-...      CNN  \n",
       "45  Each week, Shirley Raines and her team of volu...      CNN  \n",
       "46  Peloton has released a new ad in response to t...      CNN  \n",
       "47  One of the Louisville detectives who fatally s...      CNN  \n",
       "48  Gigantic superyachts have long been nicknamed ...      CNN  \n",
       "49  From Lisa Ling to the West Wing, A.C. to D.C.,...      CNN  \n",
       "50  Michigan high school shooting suspect Ethan Cr...      CNN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c9954",
   "metadata": {},
   "source": [
    "## Data Scrapping using snscrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be705ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataScraper:\n",
    "    \n",
    "    def __init__(self, channels, count=700, destdir=\".\"):\n",
    "        self.channels = channels\n",
    "        self.destdir = destdir\n",
    "        self.count = count\n",
    "        dt = str(datetime.today()).replace('-', '.')\n",
    "        dt = dt.replace(\":\", \".\")\n",
    "        self.filename = f'{dt}_{\"_\".join(channels)}.csv'\n",
    "    \n",
    "    def scrap(self, channel):\n",
    "        tweets_list1 = []\n",
    "        \n",
    "        for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'from:{channel}').get_items()): #declare a username \n",
    "            if i>self.count: #number of tweets you want to scrape\n",
    "                break\n",
    "            tweets_list1.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.lang]) #declare the attributes to be returned\n",
    "\n",
    "        # Creating a dataframe from the tweets list above \n",
    "        return pd.DataFrame(tweets_list1, columns=['Datetime', 'Tweet Id', 'Text', 'Username', 'lang'])\n",
    "    \n",
    "    def write(self, df):\n",
    "        file = f'{self.destdir}/{self.filename}'\n",
    "        print(f\"writing data file {file}\")\n",
    "        mode=\"w\"\n",
    "        if os.path.isfile(file) :\n",
    "            mode = 'a'\n",
    "        df.to_csv(f\"{self.destdir}/{self.filename}\", index=False, mode = mode)\n",
    "        pass\n",
    "    \n",
    "    def start(self):\n",
    "        for channel in self.channels:\n",
    "            print(f\"scrapping data from:{channel}\")\n",
    "            tweets = self.scrap(channel)\n",
    "            self.write(tweets)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ff665e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataScraper:\n",
    "    \n",
    "    def __init__(self, channels, start_date, end_date, count=700, destdir=\".\"):\n",
    "        self.channels = channels\n",
    "        self.destdir = destdir\n",
    "        self.count = count\n",
    "        dt = str(datetime.today()).replace('-', '.')\n",
    "        dt = dt.replace(\":\", \".\")\n",
    "        self.filename = f'{dt}_{\"_\".join(channels)}.csv'\n",
    "    \n",
    "    def scrap(self, channel):\n",
    "        tweets_list1 = []\n",
    "        \n",
    "        for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'from:{channel} since:{start_date} until:{end_date}').get_items()):\n",
    "            if i>self.count: #number of tweets you want to scrape\n",
    "                break\n",
    "            tweets_list1.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.lang]) #declare the attributes to be returned\n",
    "\n",
    "        # Creating a dataframe from the tweets list above \n",
    "        return pd.DataFrame(tweets_list1, columns=['Datetime', 'Tweet Id', 'Text', 'Username', 'lang'])\n",
    "    \n",
    "    def write(self, df):\n",
    "        file = f'{self.destdir}/{self.filename}'\n",
    "        print(f\"writing data file {file}\")\n",
    "        mode=\"w\"\n",
    "        if os.path.isfile(file) :\n",
    "            mode = 'a'\n",
    "        df.to_csv(f\"{self.destdir}/{self.filename}\", index=False, mode = mode)\n",
    "        pass\n",
    "    \n",
    "    def start(self):\n",
    "        for channel in self.channels:\n",
    "            print(f\"scrapping data from:{channel}\")\n",
    "            tweets = self.scrap(channel)\n",
    "            self.write(tweets)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0aa186f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapping data from:CNN\n",
      "writing data file ./2021.12.15 12.08.15.544012_CNN_FoxNews_BBCWorld.csv\n",
      "scrapping data from:FoxNews\n",
      "writing data file ./2021.12.15 12.08.15.544012_CNN_FoxNews_BBCWorld.csv\n",
      "scrapping data from:BBCWorld\n",
      "writing data file ./2021.12.15 12.08.15.544012_CNN_FoxNews_BBCWorld.csv\n"
     ]
    }
   ],
   "source": [
    "ds = DataScraper(['CNN', 'FoxNews', 'BBCWorld'],'2021-12-13','2021-12-14', 50)\n",
    "ds.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0337553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = DataScraper(['CNN', 'FoxNews', 'BBCWorld'],500)\n",
    "#ds.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afdc2bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"2021.12.15 00.17.34.712810_CNN_FoxNews_BBCWorld.csv\")\n",
    "data\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab0bc69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "746c0074",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreProcessor:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.stopwords = stopwords.words('english')\n",
    "    \n",
    "    def cleaning(self):\n",
    "        # remove hyperlinks\n",
    "        self.data[\"Text_cleaned\"] = self.data[\"Text\"].apply(lambda x: re.sub(r\"http\\S+\", \" \", x))\n",
    "        # remove hashtags\n",
    "        self.data[\"Text_cleaned\"] = self.data[\"Text_cleaned\"].apply(lambda x: re.sub(r\"\\#\\S+\", \" \", x))\n",
    "        # remove user tag\n",
    "        self.data[\"Text_cleaned\"] =self.data[\"Text_cleaned\"].apply(lambda x: re.sub(r\"\\@\\S+\", \" \", x))\n",
    "        # remove tweet handler\n",
    "        self.data[\"Text_cleaned\"] = self.data[\"Text_cleaned\"].apply(lambda x: re.sub(r\"\\$\\S+\", \" \", x))\n",
    "        # remove ponctuation\n",
    "        self.data[\"Text_cleaned\"] = self.data[\"Text_cleaned\"].apply(lambda x: re.sub(r\"[^A-z\\t]\", \" \", x))\n",
    "        # lowercase text\n",
    "        self.data[\"Text_cleaned\"] = self.data[\"Text_cleaned\"].apply(lambda x: x.lower())\n",
    "\n",
    "        # tokenize text\n",
    "        self.data[\"Text_cleaned\"] = self.data[\"Text_cleaned\"].apply(lambda x: nltk.word_tokenize(x))\n",
    "        # remove stop words\n",
    "        self.data[\"Text_cleaned\"] = self.data[\"Text_cleaned\"].apply(lambda x: [w for w in x if not w in self.stopwords])\n",
    "        # remove stop words\n",
    "        self.data[\"Text_cleaned\"] = self.data[\"Text_cleaned\"].apply(lambda x: [w for w in x if len(w) > 2])\n",
    "        # lemmatizing text\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        self.data[\"Text_cleaned\"] = self.data[\"Text_cleaned\"].apply(\n",
    "            lambda x: [lemmatizer.lemmatize(w, self.wordnet_pos(w)) for w in x])\n",
    "        return self.data\n",
    "    \n",
    "    def wordnet_pos(self, word):\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {'J': wordnet.ADJ,\n",
    "                    'N': wordnet.NOUN,\n",
    "                    'V': wordnet.VERB,\n",
    "                    'R': wordnet.ADV}\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "    def start(self):\n",
    "        self.cleaning()\n",
    "        \n",
    "        return self.data\n",
    "        pass\n",
    "datapreprocessor = DataPreProcessor(data)\n",
    "preprocessed_data = datapreprocessor.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd45d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapreprocessor = DataPreProcessor(data)\n",
    "preprocessed_data = datapreprocessor.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a24162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>lang</th>\n",
       "      <th>Text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-13 23:55:10+00:00</td>\n",
       "      <td>1470542846109392898</td>\n",
       "      <td>Former Brooklyn Center, Minnesota, police offi...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>en</td>\n",
       "      <td>[former, brooklyn, center, minnesota, police, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-13 23:44:12+00:00</td>\n",
       "      <td>1470540084873244672</td>\n",
       "      <td>The Omicron variant of coronavirus is spreadin...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>en</td>\n",
       "      <td>[omicron, variant, coronavirus, spread, quickl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-13 23:33:05+00:00</td>\n",
       "      <td>1470537290283982857</td>\n",
       "      <td>Hundreds of millions of devices around the wor...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>en</td>\n",
       "      <td>[hundred, million, device, around, world, coul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-13 23:22:50+00:00</td>\n",
       "      <td>1470534710669590529</td>\n",
       "      <td>Defense Secretary Lloyd Austin has decided tha...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>en</td>\n",
       "      <td>[defense, secretary, lloyd, austin, decide, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-13 23:12:11+00:00</td>\n",
       "      <td>1470532029209104386</td>\n",
       "      <td>After all these years, Bing Crosby still spurs...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>en</td>\n",
       "      <td>[year, bing, crosby, still, spur, dream, white...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Datetime             Tweet Id  \\\n",
       "0  2021-12-13 23:55:10+00:00  1470542846109392898   \n",
       "1  2021-12-13 23:44:12+00:00  1470540084873244672   \n",
       "2  2021-12-13 23:33:05+00:00  1470537290283982857   \n",
       "3  2021-12-13 23:22:50+00:00  1470534710669590529   \n",
       "4  2021-12-13 23:12:11+00:00  1470532029209104386   \n",
       "\n",
       "                                                Text Username lang  \\\n",
       "0  Former Brooklyn Center, Minnesota, police offi...      CNN   en   \n",
       "1  The Omicron variant of coronavirus is spreadin...      CNN   en   \n",
       "2  Hundreds of millions of devices around the wor...      CNN   en   \n",
       "3  Defense Secretary Lloyd Austin has decided tha...      CNN   en   \n",
       "4  After all these years, Bing Crosby still spurs...      CNN   en   \n",
       "\n",
       "                                        Text_cleaned  \n",
       "0  [former, brooklyn, center, minnesota, police, ...  \n",
       "1  [omicron, variant, coronavirus, spread, quickl...  \n",
       "2  [hundred, million, device, around, world, coul...  \n",
       "3  [defense, secretary, lloyd, austin, decide, mi...  \n",
       "4  [year, bing, crosby, still, spur, dream, white...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebde98dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=300)\n",
    "corpus = preprocessed_data[\"Text_cleaned\"].apply(lambda x: \" \".join(x))\n",
    "corpus = corpus.tolist()\n",
    "X = vectorizer.fit_transform(corpus).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffde078f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKH\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abuse</th>\n",
       "      <th>administration</th>\n",
       "      <th>age</th>\n",
       "      <th>almost</th>\n",
       "      <th>amazon</th>\n",
       "      <th>american</th>\n",
       "      <th>announce</th>\n",
       "      <th>another</th>\n",
       "      <th>ape</th>\n",
       "      <th>appear</th>\n",
       "      <th>...</th>\n",
       "      <th>watch</th>\n",
       "      <th>way</th>\n",
       "      <th>weather</th>\n",
       "      <th>wednesday</th>\n",
       "      <th>week</th>\n",
       "      <th>west</th>\n",
       "      <th>white</th>\n",
       "      <th>woman</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     abuse  administration  age  almost  amazon  american  announce  another  \\\n",
       "150    0.0             0.0  0.0     0.0     0.0       0.0       0.0      0.0   \n",
       "151    0.0             0.0  0.0     0.0     0.0       0.0       0.0      0.0   \n",
       "152    0.0             0.0  0.0     0.0     0.0       0.0       0.0      0.0   \n",
       "153    0.0             0.0  0.0     0.0     0.0       0.0       0.0      0.0   \n",
       "154    0.0             0.0  0.0     0.0     0.0       0.0       0.0      0.0   \n",
       "\n",
       "     ape  appear  ...  watch  way  weather  wednesday  week  west  white  \\\n",
       "150  0.0     0.0  ...    0.0  0.0      0.0        0.0   0.0   0.0    0.0   \n",
       "151  0.0     0.0  ...    0.0  0.0      0.0        0.0   0.0   0.0    0.0   \n",
       "152  0.0     0.0  ...    0.0  0.0      0.0        0.0   0.0   0.0    0.0   \n",
       "153  0.0     0.0  ...    0.0  0.0      0.0        0.0   0.0   0.0    0.0   \n",
       "154  0.0     0.0  ...    0.0  0.0      0.0        0.0   0.0   0.0    0.0   \n",
       "\n",
       "     woman  world  year  \n",
       "150    0.0    0.0   0.0  \n",
       "151    0.0    0.0   0.0  \n",
       "152    0.0    0.0   0.0  \n",
       "153    0.0    0.0   0.0  \n",
       "154    0.0    0.0   0.0  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X, columns=vectorizer.get_feature_names())\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c475741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKH\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\AKH\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\AKH\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.306624940867878"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model = KMeans(400)\n",
    "kmeans_model.fit(X[0:500])\n",
    "predictions = kmeans_model.predict(X[0:500])\n",
    "silhouette_score(X[0:500], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f24a7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKH\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\AKH\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features=300)\n",
    "corpus = preprocessed_data[\"Text_cleaned\"].apply(lambda x: \" \".join(x))\n",
    "corpus = corpus.tolist()\n",
    "X = vectorizer.fit_transform(corpus).todense()\n",
    "lda_model = LatentDirichletAllocation(15)\n",
    "lda_model.fit(X[0:500])\n",
    "predictions = lda_model.transform(X[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cbc1149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKH\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1284.916244566347"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.score(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc43f09",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Lemmatization doesn't working</h3>\n",
    "\n",
    "## TODOS :\n",
    "- lemmetization\n",
    "- stemmization\n",
    "- create text representation\n",
    "- train models\n",
    "- evaluation\n",
    "- label data\n",
    "- create topic tracking process\n",
    "- end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
